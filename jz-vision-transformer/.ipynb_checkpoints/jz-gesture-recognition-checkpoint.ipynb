{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079},{"sourceId":5980815,"sourceType":"datasetVersion","datasetId":3428198}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:18:17.843225Z","iopub.execute_input":"2024-07-16T17:18:17.843566Z","iopub.status.idle":"2024-07-16T17:18:34.844576Z","shell.execute_reply.started":"2024-07-16T17:18:17.843537Z","shell.execute_reply":"2024-07-16T17:18:34.843522Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.2.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.5.26)\nRequirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from mediapipe) (0.4.26)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (0.4.26.dev20240504)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe) (4.10.0.84)\nCollecting protobuf<5,>=4.25.3 (from mediapipe)\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting sounddevice>=0.4.4 (from mediapipe)\n  Downloading sounddevice-0.4.7-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (0.2.0)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (1.11.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\nDownloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\nInstalling collected packages: protobuf, sounddevice, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.3 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\ntensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport cv2\nimport mediapipe as mp\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:10.993075Z","iopub.execute_input":"2024-07-16T17:21:10.993448Z","iopub.status.idle":"2024-07-16T17:21:23.235062Z","shell.execute_reply.started":"2024-07-16T17:21:10.993419Z","shell.execute_reply":"2024-07-16T17:21:23.234220Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-16 17:21:12.724924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-16 17:21:12.725048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-16 17:21:12.825854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Paths to datasets\nvideo_path = '/kaggle/input/asl-dataset-z-and-j/UCF50'\nalphabet_path = '/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:23.236427Z","iopub.execute_input":"2024-07-16T17:21:23.237040Z","iopub.status.idle":"2024-07-16T17:21:23.241279Z","shell.execute_reply.started":"2024-07-16T17:21:23.237011Z","shell.execute_reply":"2024-07-16T17:21:23.240381Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set the number of frames to pad to\nselected_frame_dim = 180  # Example value\npadding_value = (0, 0, 0)  # Padding value","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:30.531393Z","iopub.execute_input":"2024-07-16T17:21:30.531806Z","iopub.status.idle":"2024-07-16T17:21:30.536314Z","shell.execute_reply.started":"2024-07-16T17:21:30.531774Z","shell.execute_reply":"2024-07-16T17:21:30.535309Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize Mediapipe Hands\n# Confidence level allows you to adjust the sensitivity of hand detection\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:33.537600Z","iopub.execute_input":"2024-07-16T17:21:33.538279Z","iopub.status.idle":"2024-07-16T17:21:33.550790Z","shell.execute_reply.started":"2024-07-16T17:21:33.538247Z","shell.execute_reply":"2024-07-16T17:21:33.549591Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1721150493.566159     176 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1721150493.590550     176 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Returns list of tuples of videos, with their corresponding label\ndef load_videos(path, label):\n    video_files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.avi')]\n    video_files.sort()\n    return [(f, label) for f in video_files]","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:43.677430Z","iopub.execute_input":"2024-07-16T17:21:43.677761Z","iopub.status.idle":"2024-07-16T17:21:43.683750Z","shell.execute_reply.started":"2024-07-16T17:21:43.677723Z","shell.execute_reply":"2024-07-16T17:21:43.682856Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Returns list of tuples of videos, with their corresponding label\n# Gets the corresponding image paths and appends them to a list\ndef load_images(path, labels):\n    image_files = []\n    for label in labels:\n        files = [os.path.join(path, label, f) for f in os.listdir(os.path.join(path, label)) if f.endswith('.jpg')]\n        files = random.sample(files, 5)  # Take 12 images per label\n        image_files.extend([(f, label) for f in files])\n    return image_files","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:21:49.854924Z","iopub.execute_input":"2024-07-16T17:21:49.855266Z","iopub.status.idle":"2024-07-16T17:21:49.861088Z","shell.execute_reply.started":"2024-07-16T17:21:49.855240Z","shell.execute_reply":"2024-07-16T17:21:49.860086Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Augments an image to prevent overfitting\ndef augment_image(image):\n    # Random rotation\n    angle = random.uniform(-15, 15)\n    height, width = image.shape[:2]\n    M = cv2.getRotationMatrix2D((width // 2, height // 2), angle, 1)\n    rotated = cv2.warpAffine(image, M, (width, height))\n    \n    # Random horizontal flip\n    if random.random() > 0.5:\n        rotated = cv2.flip(rotated, 1)\n    \n    # Adding random noise\n    noise = np.random.normal(0, 0.05, rotated.shape)\n    noisy_image = np.clip(rotated + noise, 0, 255).astype(np.uint8)\n    \n    return noisy_image","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:42.027115Z","iopub.execute_input":"2024-07-16T17:25:42.028036Z","iopub.status.idle":"2024-07-16T17:25:42.034840Z","shell.execute_reply.started":"2024-07-16T17:25:42.027991Z","shell.execute_reply":"2024-07-16T17:25:42.033975Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Returns the landmarks from the frames, if existing\ndef extract_landmarks_from_video(video_file):\n    cap = cv2.VideoCapture(video_file)\n    frames = []\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = augment_image(frame)  # Apply augmentation\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        results = hands.process(frame_rgb)\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                frame_landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n                frames.append(frame_landmarks)\n        else:\n            continue\n    cap.release()\n    if len(frames) == 0:\n        return None\n    return frames","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:43.917951Z","iopub.execute_input":"2024-07-16T17:25:43.918530Z","iopub.status.idle":"2024-07-16T17:25:43.925570Z","shell.execute_reply.started":"2024-07-16T17:25:43.918499Z","shell.execute_reply":"2024-07-16T17:25:43.924634Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Returns the landmarks from the images\ndef extract_landmarks_from_image(image_file):\n    image = cv2.imread(image_file)\n    if image is None:\n        return None\n    augmented_image = augment_image(image)  # Apply augmentation\n    image_rgb = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)\n    results = hands.process(image_rgb)\n    if results.multi_hand_landmarks:\n        for hand_landmarks in results.multi_hand_landmarks:\n            return [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n    return None","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:45.066939Z","iopub.execute_input":"2024-07-16T17:25:45.067659Z","iopub.status.idle":"2024-07-16T17:25:45.074064Z","shell.execute_reply.started":"2024-07-16T17:25:45.067625Z","shell.execute_reply":"2024-07-16T17:25:45.073022Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def pad_sequence(sequence, target_length, padding_value):\n    while len(sequence) < target_length:\n        sequence.append([padding_value] * 21)\n    return sequence[:target_length]","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:46.156553Z","iopub.execute_input":"2024-07-16T17:25:46.157241Z","iopub.status.idle":"2024-07-16T17:25:46.161646Z","shell.execute_reply.started":"2024-07-16T17:25:46.157212Z","shell.execute_reply":"2024-07-16T17:25:46.160794Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Load and split datasets\nvideo_files = load_videos(os.path.join(video_path, 'j'), 'J') + load_videos(os.path.join(video_path, 'z'), 'Z')\nimage_files = load_images(alphabet_path, list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'))\n\n# Tuples of video paths, with their corresponding char label\ntrain_videos, val_videos = train_test_split(video_files, test_size=0.2, random_state=42)\ntrain_images, val_images = train_test_split(image_files, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:47.053808Z","iopub.execute_input":"2024-07-16T17:25:47.054578Z","iopub.status.idle":"2024-07-16T17:25:47.320506Z","shell.execute_reply.started":"2024-07-16T17:25:47.054549Z","shell.execute_reply":"2024-07-16T17:25:47.319785Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(train_videos)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:47.804356Z","iopub.execute_input":"2024-07-16T17:25:47.805123Z","iopub.status.idle":"2024-07-16T17:25:47.810511Z","shell.execute_reply.started":"2024-07-16T17:25:47.805095Z","shell.execute_reply":"2024-07-16T17:25:47.809637Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"569"},"metadata":{}}]},{"cell_type":"code","source":"# Extract landmarks and pad sequences\ndef process_videos(video_files):\n    data = []\n    for video_file, label in tqdm(video_files, desc='Processing videos'):\n        landmarks = extract_landmarks_from_video(video_file)\n        if landmarks:\n            padded_landmarks = pad_sequence(landmarks, selected_frame_dim, padding_value)\n            data.append((padded_landmarks, label))\n    return data\n\ndef process_images(image_files):\n    data = []\n    for image_file, label in tqdm(image_files, desc='Processing images'):\n        landmarks = extract_landmarks_from_image(image_file)\n        if landmarks:\n            padded_landmarks = pad_sequence([landmarks], selected_frame_dim, padding_value)\n            data.append((padded_landmarks, label))\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:49.081778Z","iopub.execute_input":"2024-07-16T17:25:49.082369Z","iopub.status.idle":"2024-07-16T17:25:49.089677Z","shell.execute_reply.started":"2024-07-16T17:25:49.082329Z","shell.execute_reply":"2024-07-16T17:25:49.088714Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Process training and validation data\ntrain_data = process_videos(train_videos) + process_images(train_images)\nval_data = process_videos(val_videos) + process_images(val_images)\n\n# Batching and shuffling\ndef get_batches(data, batch_size):\n    random.shuffle(data)\n    for i in range(0, len(data), batch_size):\n        yield data[i:i + batch_size]\n        \ndef save_batches(data, batch_size, filename):\n    batches = list(get_batches(data, batch_size))\n    with open(filename, 'wb') as f:\n        pickle.dump(batches, f)\n\ndef load_batches(filename):\n    with open(filename, 'rb') as f:\n        batches = pickle.load(f)\n    return batches","metadata":{"execution":{"iopub.status.busy":"2024-07-16T17:25:50.104706Z","iopub.execute_input":"2024-07-16T17:25:50.105530Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Processing videos:   0%|          | 0/569 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\nProcessing videos:   1%|          | 3/569 [00:15<47:44,  5.06s/it]","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Example usage\nnum_epochs = 10\nbatch_size = 32\nfor epoch in range(num_epochs):\n    for batch in get_batches(train_data, batch_size):\n        # Train your model on the batch\n        pass\n    random.shuffle(train_data)","metadata":{},"execution_count":null,"outputs":[]}]}